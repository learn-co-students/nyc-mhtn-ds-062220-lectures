{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "**Aim**: SWBAT create and interpret a multiple linear regression model, explain the necessity of and perform basic data preparation, and explain what multicolinearity is and how to avoid it. Also, SWBAT check the assumptions of linear regression.\n",
    "\n",
    "Breaking down today's lecture:\n",
    "1. What's the point?*\n",
    "2. How does it work?\n",
    "3. Muliticolini-what? \n",
    "4. Linear Regression Data Prep\n",
    "5. Linear Regression Assumptions*\n",
    "\n",
    "*Sections with stars also apply to simple linear regression, too!*\n",
    "\n",
    "*Notebook based on Flatiron DS Immersive instructor Sean Abu's Multiple Linear Regression lecture.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# What's the point?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "You are a data scientist for the MTA. For your first project, they want you to predict the number of subway riders for each day. You decide to do a linear regression model predict the riders but need to gather data first. With a partner brainstorm a list of different variables you think would explain the number of daily riders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Why multiple linear regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Using all of the features you mentioned is _far_ more effective at predicting and understanding ridership!\n",
    "\n",
    "But, generally speaking, there are 3 major uses for (multiple) linear regression analysis.  \n",
    "\n",
    "1. Useful to **identify the strength of the effect** that the independent variables have on a dependent variable.\n",
    "    - Strong or weak relationship? \n",
    "\n",
    "\n",
    "2. **Quantitatively forecast effects or impacts of changes.**  That is, multiple linear regression analysis helps us to understand how much will the dependent variable change when we change the independent variables.  \n",
    "     - Multiple linear regression allows us to do so _comparatively_ -- does one feature have _more_ of an impact than another? \n",
    "     - Allows us the answer the question: What is the most important feature when predicting our target? \n",
    "\n",
    "\n",
    "3. **Predicts trends and other values outside your dataset.**  The multiple linear regression analysis can be used to get point estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# How does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Code\n",
    "Basically the same as what we've already learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#read in car data\n",
    "df = sns.load_dataset('mpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model_year origin                       name  \n",
       "0          70    usa  chevrolet chevelle malibu  \n",
       "1          70    usa          buick skylark 320  \n",
       "2          70    usa         plymouth satellite  \n",
       "3          70    usa              amc rebel sst  \n",
       "4          70    usa                ford torino  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# building a linear regression model using statsmodel \n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "lr_model = ols(formula='mpg~weight+horsepower+displacement+cylinders+acceleration', data=df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.708</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.704</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   186.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 16 Jul 2020</td> <th>  Prob (F-statistic):</th> <td>9.82e-101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:41:54</td>     <th>  Log-Likelihood:    </th> <td> -1120.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2252.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   386</td>      <th>  BIC:               </th> <td>   2276.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   46.2643</td> <td>    2.669</td> <td>   17.331</td> <td> 0.000</td> <td>   41.016</td> <td>   51.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -0.0052</td> <td>    0.001</td> <td>   -6.351</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th>   <td>   -0.0453</td> <td>    0.017</td> <td>   -2.716</td> <td> 0.007</td> <td>   -0.078</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>displacement</th> <td>-8.313e-05</td> <td>    0.009</td> <td>   -0.009</td> <td> 0.993</td> <td>   -0.018</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cylinders</th>    <td>   -0.3979</td> <td>    0.411</td> <td>   -0.969</td> <td> 0.333</td> <td>   -1.205</td> <td>    0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th> <td>   -0.0291</td> <td>    0.126</td> <td>   -0.231</td> <td> 0.817</td> <td>   -0.276</td> <td>    0.218</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>38.561</td> <th>  Durbin-Watson:     </th> <td>   0.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  52.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.706</td> <th>  Prob(JB):          </th> <td>3.53e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.111</td> <th>  Cond. No.          </th> <td>3.87e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.87e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.708\n",
       "Model:                            OLS   Adj. R-squared:                  0.704\n",
       "Method:                 Least Squares   F-statistic:                     186.9\n",
       "Date:                Thu, 16 Jul 2020   Prob (F-statistic):          9.82e-101\n",
       "Time:                        14:41:54   Log-Likelihood:                -1120.1\n",
       "No. Observations:                 392   AIC:                             2252.\n",
       "Df Residuals:                     386   BIC:                             2276.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       46.2643      2.669     17.331      0.000      41.016      51.513\n",
       "weight          -0.0052      0.001     -6.351      0.000      -0.007      -0.004\n",
       "horsepower      -0.0453      0.017     -2.716      0.007      -0.078      -0.012\n",
       "displacement -8.313e-05      0.009     -0.009      0.993      -0.018       0.018\n",
       "cylinders       -0.3979      0.411     -0.969      0.333      -1.205       0.409\n",
       "acceleration    -0.0291      0.126     -0.231      0.817      -0.276       0.218\n",
       "==============================================================================\n",
       "Omnibus:                       38.561   Durbin-Watson:                   0.865\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               52.737\n",
       "Skew:                           0.706   Prob(JB):                     3.53e-12\n",
       "Kurtosis:                       4.111   Cond. No.                     3.87e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.87e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Mathematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Multiple linear regression has the form:\n",
    "$$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2  + \\beta_3 X_3\\cdots + \\beta_k X_k + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Your turn #1\n",
    "Based on what we learned about simple linear regression what do each of the following represent?\n",
    "- $Y$\n",
    "- $\\beta_0$\n",
    "- $\\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### What are $\\beta_1 ... \\beta_n$? How are they computed? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "They are our coefficients of the features in the model, just like in simple linear regression. Each of coefficients represent the impact of $X_i$ on $Y$, *all other features held constant*. \n",
    "- If no other features changed, what impact would increasing $X_i$ by one unit have on the other features? \n",
    "\n",
    "\n",
    "This is essentially how they are computed! See [this article](https://online.stat.psu.edu/stat462/node/132/) for the methods used to calculate these coefficients (note: this will involve lots of linear algebra, but the article explains all the concepts you'll need to know!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## The Coefficient of Determination: Another way to think about multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Multiple linear regression is simply a linear regression with more than one predictor, or independent variables. \n",
    "\n",
    "Recall the interpretation of $R^2$ in simple linear regression:\n",
    "- $R^2$ represents the proportion of variance explained by the model. \n",
    "\n",
    "**So, we have another interpretation of multiple linear regression:**\n",
    "\n",
    "By including more predictors, we make the model more complex in an effort to account for more variance in our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Multicollinearity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### What is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Multicollinearity** occurs when \"independent\" variables in a regression model are very highly correlated. \n",
    "- Note the quotes! This is the crux of the issue. (gets into computation - invertible matrices are inherently comprised of independent columns)\n",
    "- Correlation is not the _only_ metric that can be used, though a correlation of .7 and above or .9 and above are common thresholds for \"too\" multicolinear. \n",
    "    - VIF is another metric that you can learn about [here](https://www.investopedia.com/terms/v/variance-inflation-factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "There are two basic kinds of multicollinearity:\n",
    "\n",
    "- **Structural multicollinearity:** This type occurs when we create a model term using other terms. You produce it, rather than it being inherent to the data.\n",
    "    - Ex: The salary of a baseball player in dollars and in yen are perfectly correlated \n",
    "- **Data multicollinearity:** This type of multicollinearity is present in the data itself rather than being an artifact of our model. Observational experiments are more likely to exhibit this kind of multicollinearity.\n",
    "    - Ex: How much someone exercises and how much water they drink may be highly correlated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### What Problems Do Multicollinearity Cause?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Multicollinearity causes the following two basic types of problems:\n",
    "\n",
    "- The coefficient estimates can swing wildly based on which other independent variables are in the model. The **coefficients become very sensitive to small changes in the model**.\n",
    "- Multicollinearity **reduces the precision of the estimate coefficients, which weakens the statistical power of your regression model**. You might not be able to trust the p-values to identify independent variables that are statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Do I Have to Fix Multicollinearity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The need to reduce multicollinearity depends on its severity and your primary goal for your regression model. Keep the following three points in mind:\n",
    "\n",
    "- The **severity of the problems increases with the degree of the multicollinearity**. Therefore, if you have only moderate multicollinearity, you may not need to resolve it.\n",
    "- Multicollinearity **affects only the specific independent variables that are correlated**. Therefore, if multicollinearity is not present for the independent variables that you are particularly interested in, you may not need to resolve it. \n",
    "- Multicollinearity **affects the coefficients and p-values, but it does not influence the predictions**, precision of the predictions, and the goodness-of-fit statistics. If your primary goal is to make predictions, and you don’t need to understand the role of each independent variable, you don’t need to reduce severe multicollinearity.\n",
    "\n",
    "***That being said, the easiest way to deal with multicollinearity is just to remove one of the variables.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Code time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mpg</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.775396</td>\n",
       "      <td>-0.804203</td>\n",
       "      <td>-0.778427</td>\n",
       "      <td>-0.831741</td>\n",
       "      <td>0.420289</td>\n",
       "      <td>0.579267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cylinders</td>\n",
       "      <td>-0.775396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950721</td>\n",
       "      <td>0.842983</td>\n",
       "      <td>0.896017</td>\n",
       "      <td>-0.505419</td>\n",
       "      <td>-0.348746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>displacement</td>\n",
       "      <td>-0.804203</td>\n",
       "      <td>0.950721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897257</td>\n",
       "      <td>0.932824</td>\n",
       "      <td>-0.543684</td>\n",
       "      <td>-0.370164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>horsepower</td>\n",
       "      <td>-0.778427</td>\n",
       "      <td>0.842983</td>\n",
       "      <td>0.897257</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864538</td>\n",
       "      <td>-0.689196</td>\n",
       "      <td>-0.416361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>weight</td>\n",
       "      <td>-0.831741</td>\n",
       "      <td>0.896017</td>\n",
       "      <td>0.932824</td>\n",
       "      <td>0.864538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.417457</td>\n",
       "      <td>-0.306564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>acceleration</td>\n",
       "      <td>0.420289</td>\n",
       "      <td>-0.505419</td>\n",
       "      <td>-0.543684</td>\n",
       "      <td>-0.689196</td>\n",
       "      <td>-0.417457</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.288137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>model_year</td>\n",
       "      <td>0.579267</td>\n",
       "      <td>-0.348746</td>\n",
       "      <td>-0.370164</td>\n",
       "      <td>-0.416361</td>\n",
       "      <td>-0.306564</td>\n",
       "      <td>0.288137</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mpg  cylinders  displacement  horsepower    weight  \\\n",
       "mpg           1.000000  -0.775396     -0.804203   -0.778427 -0.831741   \n",
       "cylinders    -0.775396   1.000000      0.950721    0.842983  0.896017   \n",
       "displacement -0.804203   0.950721      1.000000    0.897257  0.932824   \n",
       "horsepower   -0.778427   0.842983      0.897257    1.000000  0.864538   \n",
       "weight       -0.831741   0.896017      0.932824    0.864538  1.000000   \n",
       "acceleration  0.420289  -0.505419     -0.543684   -0.689196 -0.417457   \n",
       "model_year    0.579267  -0.348746     -0.370164   -0.416361 -0.306564   \n",
       "\n",
       "              acceleration  model_year  \n",
       "mpg               0.420289    0.579267  \n",
       "cylinders        -0.505419   -0.348746  \n",
       "displacement     -0.543684   -0.370164  \n",
       "horsepower       -0.689196   -0.416361  \n",
       "weight           -0.417457   -0.306564  \n",
       "acceleration      1.000000    0.288137  \n",
       "model_year        0.288137    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(df.corr())\n",
    "plt.xticks(range(len(df.columns)), df.columns)\n",
    "plt.yticks(range(len(df.columns)), df.columns)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Ooof, that's one ugly heatmap -- let's make a better one so we can really see what's going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Create a Better Looking Heatmap with Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up  matplotlib figure (might have to play around with the \n",
    "# figsize if your labels aren't so legible and you don't want\n",
    "# to mess with the labels using matplotlib)\n",
    "f, ax = plt.subplots(figsize=(10, 9))\n",
    "\n",
    "# Create an upper triangular matrix to use to get rid of duplicate/\n",
    "# useless values\n",
    "mask = np.zeros_like(df.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# plot the heatmap\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax = sns.heatmap(df.corr(), mask=mask, square=True)\n",
    "    \n",
    "# fix for mpl bug that cuts off top/bottom of seaborn viz\n",
    "# credit: https://github.com/mwaskom/seaborn/issues/1773 SalMac86's post\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.show() # ta-da!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Much better! Now, you try running a model with the appropriate, non-correlated, features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Rerun the model after removing the highly correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.808</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.806</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   413.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 19 Jul 2020</td> <th>  Prob (F-statistic):</th> <td>1.97e-139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:39:11</td>     <th>  Log-Likelihood:    </th> <td> -1054.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   398</td>      <th>  AIC:               </th> <td>   2118.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   393</td>      <th>  BIC:               </th> <td>   2138.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>  -13.7070</td> <td>    4.052</td> <td>   -3.383</td> <td> 0.001</td> <td>  -21.673</td> <td>   -5.741</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cylinders</th>    <td>   -0.2516</td> <td>    0.329</td> <td>   -0.766</td> <td> 0.444</td> <td>   -0.898</td> <td>    0.394</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>displacement</th> <td>    0.0047</td> <td>    0.007</td> <td>    0.707</td> <td> 0.480</td> <td>   -0.008</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -0.0068</td> <td>    0.001</td> <td>  -11.811</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>model_year</th>   <td>    0.7595</td> <td>    0.051</td> <td>   15.007</td> <td> 0.000</td> <td>    0.660</td> <td>    0.859</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>42.235</td> <th>  Durbin-Watson:     </th> <td>   1.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  70.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.665</td> <th>  Prob(JB):          </th> <td>5.14e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.573</td> <th>  Cond. No.          </th> <td>7.28e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.28e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.808\n",
       "Model:                            OLS   Adj. R-squared:                  0.806\n",
       "Method:                 Least Squares   F-statistic:                     413.9\n",
       "Date:                Sun, 19 Jul 2020   Prob (F-statistic):          1.97e-139\n",
       "Time:                        13:39:11   Log-Likelihood:                -1054.0\n",
       "No. Observations:                 398   AIC:                             2118.\n",
       "Df Residuals:                     393   BIC:                             2138.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept      -13.7070      4.052     -3.383      0.001     -21.673      -5.741\n",
       "cylinders       -0.2516      0.329     -0.766      0.444      -0.898       0.394\n",
       "displacement     0.0047      0.007      0.707      0.480      -0.008       0.018\n",
       "weight          -0.0068      0.001    -11.811      0.000      -0.008      -0.006\n",
       "model_year       0.7595      0.051     15.007      0.000       0.660       0.859\n",
       "==============================================================================\n",
       "Omnibus:                       42.235   Durbin-Watson:                   1.223\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               70.410\n",
       "Skew:                           0.665   Prob(JB):                     5.14e-16\n",
       "Kurtosis:                       4.573   Cond. No.                     7.28e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.28e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_model = ols(formula='mpg~____', data=____).fit()\n",
    "mlr_model.____()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Linear Regression Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Handling Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usa       249\n",
       "japan      79\n",
       "europe     70\n",
       "Name: origin, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['origin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "For the column of `origin`, we can see that the values come through as strings that represent a category.  We can not put a string through as a value for a linear model. Instead we use dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "A **dummy variable** (aka, an indicator variable) is a numeric variable that represents categorical data, such as gender, race, political affiliation, etc.\n",
    "- Typically, 1 represents the presence of a qualitative attribute, and 0 represents the absence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>europe</th>\n",
       "      <th>japan</th>\n",
       "      <th>usa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     europe  japan  usa\n",
       "0         0      0    1\n",
       "1         0      0    1\n",
       "2         0      0    1\n",
       "3         0      0    1\n",
       "4         0      0    1\n",
       "..      ...    ...  ...\n",
       "393       0      0    1\n",
       "394       1      0    0\n",
       "395       0      0    1\n",
       "396       0      0    1\n",
       "397       0      0    1\n",
       "\n",
       "[398 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df['origin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "By creating these dummy variables. We can now include them in the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>name</th>\n",
       "      <th>origin_europe</th>\n",
       "      <th>origin_japan</th>\n",
       "      <th>origin_usa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>ford torino</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>ford mustang gl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>vw pickup</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>dodge rampage</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>ford ranger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>chevy s-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0    18.0          8         307.0       130.0    3504          12.0   \n",
       "1    15.0          8         350.0       165.0    3693          11.5   \n",
       "2    18.0          8         318.0       150.0    3436          11.0   \n",
       "3    16.0          8         304.0       150.0    3433          12.0   \n",
       "4    17.0          8         302.0       140.0    3449          10.5   \n",
       "..    ...        ...           ...         ...     ...           ...   \n",
       "393  27.0          4         140.0        86.0    2790          15.6   \n",
       "394  44.0          4          97.0        52.0    2130          24.6   \n",
       "395  32.0          4         135.0        84.0    2295          11.6   \n",
       "396  28.0          4         120.0        79.0    2625          18.6   \n",
       "397  31.0          4         119.0        82.0    2720          19.4   \n",
       "\n",
       "     model_year                       name  origin_europe  origin_japan  \\\n",
       "0            70  chevrolet chevelle malibu              0             0   \n",
       "1            70          buick skylark 320              0             0   \n",
       "2            70         plymouth satellite              0             0   \n",
       "3            70              amc rebel sst              0             0   \n",
       "4            70                ford torino              0             0   \n",
       "..          ...                        ...            ...           ...   \n",
       "393          82            ford mustang gl              0             0   \n",
       "394          82                  vw pickup              1             0   \n",
       "395          82              dodge rampage              0             0   \n",
       "396          82                ford ranger              0             0   \n",
       "397          82                 chevy s-10              0             0   \n",
       "\n",
       "     origin_usa  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "..          ...  \n",
       "393           1  \n",
       "394           0  \n",
       "395           1  \n",
       "396           1  \n",
       "397           1  \n",
       "\n",
       "[398 rows x 11 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(df, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.720</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.715</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   164.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 19 Jul 2020</td> <th>  Prob (F-statistic):</th> <td>4.20e-103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:00:21</td>     <th>  Log-Likelihood:    </th> <td> -1111.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2238.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   385</td>      <th>  BIC:               </th> <td>   2265.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>   43.7601</td> <td>    2.502</td> <td>   17.488</td> <td> 0.000</td> <td>   38.840</td> <td>   48.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>        <td>   -0.0044</td> <td>    0.001</td> <td>   -5.956</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th>    <td>   -0.0548</td> <td>    0.016</td> <td>   -3.433</td> <td> 0.001</td> <td>   -0.086</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cylinders</th>     <td>   -0.2515</td> <td>    0.307</td> <td>   -0.820</td> <td> 0.412</td> <td>   -0.854</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th>  <td>   -0.0454</td> <td>    0.123</td> <td>   -0.369</td> <td> 0.712</td> <td>   -0.287</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>origin_europe</th> <td>    0.8492</td> <td>    0.663</td> <td>    1.282</td> <td> 0.201</td> <td>   -0.454</td> <td>    2.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>origin_japan</th>  <td>    2.6731</td> <td>    0.661</td> <td>    4.043</td> <td> 0.000</td> <td>    1.373</td> <td>    3.973</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>38.033</td> <th>  Durbin-Watson:     </th> <td>   0.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  54.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.676</td> <th>  Prob(JB):          </th> <td>1.47e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.229</td> <th>  Cond. No.          </th> <td>3.71e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.71e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.720\n",
       "Model:                            OLS   Adj. R-squared:                  0.715\n",
       "Method:                 Least Squares   F-statistic:                     164.8\n",
       "Date:                Sun, 19 Jul 2020   Prob (F-statistic):          4.20e-103\n",
       "Time:                        14:00:21   Log-Likelihood:                -1111.8\n",
       "No. Observations:                 392   AIC:                             2238.\n",
       "Df Residuals:                     385   BIC:                             2265.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept        43.7601      2.502     17.488      0.000      38.840      48.680\n",
       "weight           -0.0044      0.001     -5.956      0.000      -0.006      -0.003\n",
       "horsepower       -0.0548      0.016     -3.433      0.001      -0.086      -0.023\n",
       "cylinders        -0.2515      0.307     -0.820      0.412      -0.854       0.351\n",
       "acceleration     -0.0454      0.123     -0.369      0.712      -0.287       0.196\n",
       "origin_europe     0.8492      0.663      1.282      0.201      -0.454       2.152\n",
       "origin_japan      2.6731      0.661      4.043      0.000       1.373       3.973\n",
       "==============================================================================\n",
       "Omnibus:                       38.033   Durbin-Watson:                   0.921\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               54.486\n",
       "Skew:                           0.676   Prob(JB):                     1.47e-12\n",
       "Kurtosis:                       4.229   Cond. No.                     3.71e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.71e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model = ols(formula='mpg~weight+horsepower+cylinders+acceleration+origin_europe+origin_japan', data=dummy_df).fit()\n",
    "dummy_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**But wait!, you say. We didn't include the `origin_usa` column in this model!**\n",
    "\n",
    "- That dummy variable would redundant; it carries no new information. What issue that we've discussed does this relate to? \n",
    "    - Hint: If we know the value of the `origin_europe` and the `origin'japan` columns, then we also know the value of the `origin_usa` column.\n",
    "\n",
    "Using all the dummy variables derived from a category is known as the dummy variable trap. Avoid this trap!\n",
    "- Either don't include in the model _or_ use the parameter `drop_first=True` (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>name</th>\n",
       "      <th>origin_japan</th>\n",
       "      <th>origin_usa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>ford torino</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>ford mustang gl</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>vw pickup</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>dodge rampage</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>ford ranger</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>chevy s-10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0    18.0          8         307.0       130.0    3504          12.0   \n",
       "1    15.0          8         350.0       165.0    3693          11.5   \n",
       "2    18.0          8         318.0       150.0    3436          11.0   \n",
       "3    16.0          8         304.0       150.0    3433          12.0   \n",
       "4    17.0          8         302.0       140.0    3449          10.5   \n",
       "..    ...        ...           ...         ...     ...           ...   \n",
       "393  27.0          4         140.0        86.0    2790          15.6   \n",
       "394  44.0          4          97.0        52.0    2130          24.6   \n",
       "395  32.0          4         135.0        84.0    2295          11.6   \n",
       "396  28.0          4         120.0        79.0    2625          18.6   \n",
       "397  31.0          4         119.0        82.0    2720          19.4   \n",
       "\n",
       "     model_year                       name  origin_japan  origin_usa  \n",
       "0            70  chevrolet chevelle malibu             0           1  \n",
       "1            70          buick skylark 320             0           1  \n",
       "2            70         plymouth satellite             0           1  \n",
       "3            70              amc rebel sst             0           1  \n",
       "4            70                ford torino             0           1  \n",
       "..          ...                        ...           ...         ...  \n",
       "393          82            ford mustang gl             0           1  \n",
       "394          82                  vw pickup             0           0  \n",
       "395          82              dodge rampage             0           1  \n",
       "396          82                ford ranger             0           1  \n",
       "397          82                 chevy s-10             0           1  \n",
       "\n",
       "[398 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df, columns=['origin'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Interpreting the coefficients of Dummy Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Look at our model output from above. If a car originated in Japan, it will have a value of 1 for the variable `origin_japan`. So we would multiply the value of 1 by the coefficient for that variable and add that to our final MPG prediction.  \n",
    "\n",
    "If the car orginated in the USA it would have a value of zero for both the `origin_japan` and `origin_europe` columns. Therefore, the coefficients for those variables who not impact the final prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Scaling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Most of the times, your dataset will contain features highly varying in magnitudes, units and range (ex: acceleration and range). For linear regression models, this makes it difficult to compare the sizes of the coefficients for different variables. We want to **get everything on the same scale so that nothing comes accross as more or less important because of the way it's measured**.\n",
    "\n",
    "Three common ways to scale the data are:\n",
    "1. **Standardization**: This redistributes the features with their mean μ = 0 and standard deviation σ =1 . `sklearn.preprocessing.scale` helps us implementing standardization in python. \n",
    "$$x' =\\frac{x-\\bar{x}}{\\sigma}$$\n",
    "\n",
    "2. **Mean Normalization**: This distribution will have values between -1 and 1 with μ=0.\n",
    "\n",
    "$$x' =\\frac{x-\\bar{x}}{max(x)- min(x)}$$\n",
    "\n",
    "3. **Min-Max Scaling**: This scaling brings the value between 0 and 1.\n",
    "\n",
    "$$x' =\\frac{x-min(x)}{max(x)- min(x)}$$\n",
    "\n",
    "\n",
    "\n",
    "https://medium.com/@swethalakshmanan14/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get rid of origin_usa because of multicollinearity and \n",
    "# name because it's a string\n",
    "dummy_df.drop(['name', 'origin_usa'], axis=1, inplace=True)\n",
    "scaled_df = scaler.fit_transform(dummy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset= ['cylinders', 'horsepower', 'weight',\n",
    "       'acceleration', 'origin_europe', 'origin_japan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_scaled = []\n",
    "for var in subset:\n",
    "    new_col = var +\"_scaled\"\n",
    "    dummy_df[new_col] = scaler.fit_transform(dummy_df[[var]])\n",
    "    subset_scaled.append(new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin_europe</th>\n",
       "      <th>origin_japan</th>\n",
       "      <th>cylinders_scaled</th>\n",
       "      <th>horsepower_scaled</th>\n",
       "      <th>weight_scaled</th>\n",
       "      <th>acceleration_scaled</th>\n",
       "      <th>origin_europe_scaled</th>\n",
       "      <th>origin_japan_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.498191</td>\n",
       "      <td>0.664133</td>\n",
       "      <td>0.630870</td>\n",
       "      <td>-1.295498</td>\n",
       "      <td>-0.461968</td>\n",
       "      <td>-0.497643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.498191</td>\n",
       "      <td>1.574594</td>\n",
       "      <td>0.854333</td>\n",
       "      <td>-1.477038</td>\n",
       "      <td>-0.461968</td>\n",
       "      <td>-0.497643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.498191</td>\n",
       "      <td>1.184397</td>\n",
       "      <td>0.550470</td>\n",
       "      <td>-1.658577</td>\n",
       "      <td>-0.461968</td>\n",
       "      <td>-0.497643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.498191</td>\n",
       "      <td>1.184397</td>\n",
       "      <td>0.546923</td>\n",
       "      <td>-1.295498</td>\n",
       "      <td>-0.461968</td>\n",
       "      <td>-0.497643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.498191</td>\n",
       "      <td>0.924265</td>\n",
       "      <td>0.565841</td>\n",
       "      <td>-1.840117</td>\n",
       "      <td>-0.461968</td>\n",
       "      <td>-0.497643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.856321</td>\n",
       "      <td>-0.480448</td>\n",
       "      <td>-0.213324</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>-0.461968</td>\n",
       "      <td>-0.497643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.856321</td>\n",
       "      <td>-1.364896</td>\n",
       "      <td>-0.993671</td>\n",
       "      <td>3.279296</td>\n",
       "      <td>2.164651</td>\n",
       "      <td>-0.497643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.856321</td>\n",
       "      <td>-0.532474</td>\n",
       "      <td>-0.798585</td>\n",
       "      <td>-1.440730</td>\n",
       "      <td>-0.461968</td>\n",
       "      <td>-0.497643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.856321</td>\n",
       "      <td>-0.662540</td>\n",
       "      <td>-0.408411</td>\n",
       "      <td>1.100822</td>\n",
       "      <td>-0.461968</td>\n",
       "      <td>-0.497643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.856321</td>\n",
       "      <td>-0.584501</td>\n",
       "      <td>-0.296088</td>\n",
       "      <td>1.391285</td>\n",
       "      <td>-0.461968</td>\n",
       "      <td>-0.497643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0    18.0          8         307.0       130.0    3504          12.0   \n",
       "1    15.0          8         350.0       165.0    3693          11.5   \n",
       "2    18.0          8         318.0       150.0    3436          11.0   \n",
       "3    16.0          8         304.0       150.0    3433          12.0   \n",
       "4    17.0          8         302.0       140.0    3449          10.5   \n",
       "..    ...        ...           ...         ...     ...           ...   \n",
       "393  27.0          4         140.0        86.0    2790          15.6   \n",
       "394  44.0          4          97.0        52.0    2130          24.6   \n",
       "395  32.0          4         135.0        84.0    2295          11.6   \n",
       "396  28.0          4         120.0        79.0    2625          18.6   \n",
       "397  31.0          4         119.0        82.0    2720          19.4   \n",
       "\n",
       "     model_year  origin_europe  origin_japan  cylinders_scaled  \\\n",
       "0            70              0             0          1.498191   \n",
       "1            70              0             0          1.498191   \n",
       "2            70              0             0          1.498191   \n",
       "3            70              0             0          1.498191   \n",
       "4            70              0             0          1.498191   \n",
       "..          ...            ...           ...               ...   \n",
       "393          82              0             0         -0.856321   \n",
       "394          82              1             0         -0.856321   \n",
       "395          82              0             0         -0.856321   \n",
       "396          82              0             0         -0.856321   \n",
       "397          82              0             0         -0.856321   \n",
       "\n",
       "     horsepower_scaled  weight_scaled  acceleration_scaled  \\\n",
       "0             0.664133       0.630870            -1.295498   \n",
       "1             1.574594       0.854333            -1.477038   \n",
       "2             1.184397       0.550470            -1.658577   \n",
       "3             1.184397       0.546923            -1.295498   \n",
       "4             0.924265       0.565841            -1.840117   \n",
       "..                 ...            ...                  ...   \n",
       "393          -0.480448      -0.213324             0.011586   \n",
       "394          -1.364896      -0.993671             3.279296   \n",
       "395          -0.532474      -0.798585            -1.440730   \n",
       "396          -0.662540      -0.408411             1.100822   \n",
       "397          -0.584501      -0.296088             1.391285   \n",
       "\n",
       "     origin_europe_scaled  origin_japan_scaled  \n",
       "0               -0.461968            -0.497643  \n",
       "1               -0.461968            -0.497643  \n",
       "2               -0.461968            -0.497643  \n",
       "3               -0.461968            -0.497643  \n",
       "4               -0.461968            -0.497643  \n",
       "..                    ...                  ...  \n",
       "393             -0.461968            -0.497643  \n",
       "394              2.164651            -0.497643  \n",
       "395             -0.461968            -0.497643  \n",
       "396             -0.461968            -0.497643  \n",
       "397             -0.461968            -0.497643  \n",
       "\n",
       "[398 rows x 15 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.720</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.715</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   164.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 19 Jul 2020</td> <th>  Prob (F-statistic):</th> <td>4.20e-103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:11:08</td>     <th>  Log-Likelihood:    </th> <td> -1111.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2238.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   385</td>      <th>  BIC:               </th> <td>   2265.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>   23.4747</td> <td>    0.210</td> <td>  111.564</td> <td> 0.000</td> <td>   23.061</td> <td>   23.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight_scaled</th>        <td>   -3.7487</td> <td>    0.629</td> <td>   -5.956</td> <td> 0.000</td> <td>   -4.986</td> <td>   -2.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower_scaled</th>    <td>   -2.1054</td> <td>    0.613</td> <td>   -3.433</td> <td> 0.001</td> <td>   -3.311</td> <td>   -0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cylinders_scaled</th>     <td>   -0.4273</td> <td>    0.521</td> <td>   -0.820</td> <td> 0.412</td> <td>   -1.451</td> <td>    0.597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration_scaled</th>  <td>   -0.1250</td> <td>    0.338</td> <td>   -0.369</td> <td> 0.712</td> <td>   -0.790</td> <td>    0.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>origin_europe_scaled</th> <td>    0.3233</td> <td>    0.252</td> <td>    1.282</td> <td> 0.201</td> <td>   -0.173</td> <td>    0.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>origin_japan_scaled</th>  <td>    1.0662</td> <td>    0.264</td> <td>    4.043</td> <td> 0.000</td> <td>    0.548</td> <td>    1.585</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>38.033</td> <th>  Durbin-Watson:     </th> <td>   0.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  54.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.676</td> <th>  Prob(JB):          </th> <td>1.47e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.229</td> <th>  Cond. No.          </th> <td>    7.44</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.720\n",
       "Model:                            OLS   Adj. R-squared:                  0.715\n",
       "Method:                 Least Squares   F-statistic:                     164.8\n",
       "Date:                Sun, 19 Jul 2020   Prob (F-statistic):          4.20e-103\n",
       "Time:                        14:11:08   Log-Likelihood:                -1111.8\n",
       "No. Observations:                 392   AIC:                             2238.\n",
       "Df Residuals:                     385   BIC:                             2265.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept               23.4747      0.210    111.564      0.000      23.061      23.888\n",
       "weight_scaled           -3.7487      0.629     -5.956      0.000      -4.986      -2.511\n",
       "horsepower_scaled       -2.1054      0.613     -3.433      0.001      -3.311      -0.900\n",
       "cylinders_scaled        -0.4273      0.521     -0.820      0.412      -1.451       0.597\n",
       "acceleration_scaled     -0.1250      0.338     -0.369      0.712      -0.790       0.540\n",
       "origin_europe_scaled     0.3233      0.252      1.282      0.201      -0.173       0.819\n",
       "origin_japan_scaled      1.0662      0.264      4.043      0.000       0.548       1.585\n",
       "==============================================================================\n",
       "Omnibus:                       38.033   Durbin-Watson:                   0.921\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               54.486\n",
       "Skew:                           0.676   Prob(JB):                     1.47e-12\n",
       "Kurtosis:                       4.229   Cond. No.                         7.44\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_model = ols(formula='mpg~weight_scaled+horsepower_scaled+cylinders_scaled+acceleration_scaled+origin_europe_scaled+origin_japan_scaled', data=dummy_df).fit()\n",
    "scaled_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "🚗 🚕 🚙 🚌 🚎 🏎 🚓 🚚 🚛 🚜 🚗 🚕 🚙 🚌 🚎 🏎 🚓 🚚 🚛 🚜 🚗 🚕 🚙 🚌 🚎 🏎 🚓 🚚 🚛 🚜 🚗 🚕 🚙 🚌 🚎 🏎 🚓 🚚 🚛 🚜\n",
    "\n",
    "Now our coefficients are on a similiar scale which allows us to compare the size of the coeffiecents to make some inferences about which features have a bigger impact on the MPG of a car. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Linear Regression Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## 1. There is a linear relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This model _cannot_ model non-linear relationships, as discussed previously!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## 2. Independence of Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Columns should be independent, but we also cannot have one row depend on the next.\n",
    "\n",
    "Ex: If you shuffled the rows, would the data still make sense?\n",
    "- One example where this would not be the case - stock prices! Each day is related to the last (theoretically?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## 3. Errors are normally distributed and 4. Homescedasticity of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Basically, when we plot our residuals, we don't want to see a trend in what we get wrong.\n",
    "\n",
    "<img src='https://www.jmp.com/en_us/statistics-knowledge-portal/what-is-regression/simple-linear-regression-assumptions/_jcr_content/par/styledcontainer_2069/par/lightbox_e99c/lightboxImage.img.png/1548702854476.png' width=700>\n",
    "\n",
    "<img src='https://www.jmp.com/en_us/statistics-knowledge-portal/what-is-regression/simple-linear-regression-assumptions/_jcr_content/par/styledcontainer_2069/par/lightbox_7320/lightboxImage.img.png/1548702854735.png' width=700>\n",
    "\n",
    "<img src='https://www.jmp.com/en_us/statistics-knowledge-portal/what-is-regression/simple-linear-regression-assumptions/_jcr_content/par/styledcontainer_2069/par/lightbox_dccd/lightboxImage.img.png/1548702855060.png' width=700>\n",
    "\n",
    "[Source](https://www.jmp.com/en_us/statistics-knowledge-portal/what-is-regression/simple-linear-regression-assumptions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Other resources to consult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Everything about regression:  https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-tutorial-and-examples\n",
    "\n",
    "Statsmodels example: https://datatofish.com/statsmodels-linear-regression/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
